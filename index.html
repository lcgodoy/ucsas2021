<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Web Scraping for Sports Data with R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Lucas da Cunha Godoy" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Web Scraping for Sports Data with R
## UCSAS 2021
### Lucas da Cunha Godoy
### October 2021

---








## Outline

* Intro
* Basic notions about `HTML` and web scraping
* The `rvest` package
* Examples and Exercises

---

class: center, middle, inverse

# Introduction

---

## Introduction

--

* Web scraping technique is used for capturing data from websites.

--

* It is extremely useful for extracting unstructured data (e.g. text data)
  and/or data available **only** through web pages.

--

* A reproducible way of capturing data online
  
--
  
&gt; Web scraping scripts need to be updated periodically, it is common for these
&gt; scripts to become deprecated due to unexpected changes on the websites where
&gt; they are contained.

---

## Introduction

* The two most popular `R` packages for web scraping are the
  [`rvest`](https://rvest.tidyverse.org/) and the
  [`RSelenium`](https://docs.ropensci.org/RSelenium/).
  
--

* The latter is more flexible and, consequently, more complicated to deal
  with. It requires us to set up a local server, and the process to do so
  depends on your OS. One option to make it work independently of the OS is to
  us [Docker](https://docs.ropensci.org/RSelenium/). This topic is not in the
  scope of this course.
  
--
  
* Here we will focus on `rvest` which follows the "tidyverse" structure and
  style.

---

## Prerequisites

* Having experience with `R`

* A laptop with `R` and Rstudio installed
 
* `rvest`, `dplyr`, `janitor`, and `ggplot2` packages will be needed. To install the
  packages run  
  

```r
install.packages(c("rvest", "dplyr", "ggplot2", "janitor"),
                 repos = "https://cloud.r-project.org/")
```

---

class: middle, center, inverse

# Basic notions about `HTML` and web scraping

---

## What is `HTML`?


* `HTML` stands for *Hipertext Markup Language*

--

* It's a language used to "build" (or represent) websites.

--

* When we open a website using a web browser it translates the `HTML` code into
  a visual representation.

--

* There are many technologies used jointly with `HTML` to make websites look
  nicer and, sometimes, safer. Some examples are `javascript` and `CSS`.

---

## How does a `.html` file looks like?

The visual representation of the `html` code below can be seen in
[here](https://webscraping-tures.github.io/hello_world.html).

```
&lt;!DOCTYPE html&gt;

&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Hello World!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;b&gt;Hello World!&lt;/b&gt;
  &lt;/body&gt;
&lt;/html&gt;
```

&gt; Example from https://jakobtures.github.io/web-scraping/html.html .

&lt;!-- * There are many elements in `html`. We do not have time to cover all of --&gt;
&lt;!--   them. Let's focus on some important tags that might be useful to extract data. --&gt;

---

## Tags, ids, classes, attributes
  
* **html** 
    - The whole content of a website is usually part of this tag.
* **head** 
    - Contains metadata abou the page/document. For instance, its title and
      helper scripts in other languages, such as `js` and `css`.
* **title** 
    - Title of the page.
* **body** 
    - Primary visual content. Everything not within the header is usually
      included under this tag.
* **h1, h2, h3, h4** 
    - Different levels of headers within the document. 
* **p** 
    - a paragraph.
* **ul, ol, li** 
    - unordered, and ordered lists and their elements.
* **table, th, tr, td** 
    - Table, table header, table row, and table content, respectively.

---

## Tags, ids, classes, attributes

- Each one of the previously displayed tags might have their own "ids",
  "classes", and "attributes". The ids and classes will be responsible to
  customize different tags.

- For example, the web developer might want to define a different style for some
  specific paragraphs and/or tables. This can be achieved by assigning different
  classes for these tags.
  
- Usually, `css` is used to define these styling options.

---

## Static and Dynamic Data

* Most of data in the web are not organized into files, which can be directly
  imported into R.

* Before we capture these data, we need to determine whether the data are static
  or dynamic based on the source code.

* Unfortunately, there is no general rule to determine wheter the data provided
  by a website is static or dynamic and it needs to be done in a case by case
  basis.

---

## Differences between static and dynamic data

* As the name suggests, static data is static. That is, once the website is
  loaded, all the data is available (even though it might be hidden by some
  button).
  
* Sometimes it is possible to determine wheter the data is static by looking at
  the source code of the webpage. 

* Note that, even if we don't find the data itself in the source code, it might
  be static.

* Most of modern websites rely on servers to store, retrieve, and or manipulate
  the data. Dynamic data is not available until you "request" it by clicking at
  some button or making a search.

---


* Note that, the source code can be accessed by View `\(\rightarrow\)` Developer
  `\(\rightarrow\)` View Source in Chrome. Or right click the website and choose
  "View Page Source".


&lt;img src="img/web_dev.png" width="85%" style="display: block; margin: auto;" /&gt;

---

## Web Scraping Using R

* Different web scraping techniques are required when we are facing different
  kinds of data.

* Data have been organized into files.

  - Directly download it and read it in R

* Data are contained in HTML pages.

  - Static data
  - Dynamic data

---

## Import Data Files from Websites

* These files that can be read by **read.csv** or related functions.

* They can be directly imported from a URL.

- Example: we extract the most recent Australian Open Tennis Championships match
  [(AUS Open)](http://www.tennis-data.co.uk/ausopen.php):


```r
url &lt;- "http://www.tennis-data.co.uk/2020/ausopen.csv"
tennis_aus &lt;- read.csv(url)
str(tennis_aus)
```

---

## Web Scraping for Static Data in R

R provides several approaches for web scraping the static data. Two of them will
be discussed in this workshop.

* **readLines** function: Read the source code of the HTML pages.

* **rvest** package: Capture useful data by identifying the elements contains
  the data in the source code.

---

## Example

.pull-left[

[College basketball school index](https://www.sports-reference.com/cbb/schools/)

* These data can be obtained by copying and pasting manually.

* Web scraping technique helps capture the data efficiently.
]

.pull-right[
&lt;img src="img/basketball.png" width="90%" style="display: block; margin: auto;" /&gt;
]

---

## Web Scraping for Static Data in R

Use **readLines** function for [College basketball school
index](https://www.sports-reference.com/cbb/schools/).


```r
web_page &lt;- readLines("https://www.sports-reference.com/cbb/schools/")
head(web_page, n = 10L)
```

* Gives the source code.

* Needs data cleaning and organization using [regular
  expressions](https://en.wikipedia.org/wiki/Regular_expression).

---

## Web Scraping for Static Data in R

Before we talk about web scraping by **rvest** package, we need to know how to
locate the elements containing the data in the source code.

* Right click the page and choose "Inspect".

* Click "Select an element in the page to inspect it".

* We can locate the elements by CSS selector or XPATH.

* [SelectorGadget](https://rvest.tidyverse.org/articles/selectorgadget.html) is
  a convenient tool to identify CSS selector.

---

## Web Scraping for Static Data in R

Use http://tennisabstract.com/reports/atp_elo_ratings.html as an example

.pull-left[

* CSS selector: id = "reportable", class = "tablesorter"

&lt;img src="img/css.png" width="85%" style="display: block; margin: auto;" /&gt;
]

.pull-right[

* XPATH: '//*[@id="reportable"]'

&lt;img src="img/xpath.png" width="85%" style="display: block; margin: auto;" /&gt;
]

---

class: middle, center, inverse

# The `rvest` package

---

## `rvest`

- An `R` package that is part of the `tidyverse` "collection" of packages

- The package has only one system dependencie which is the `libxlm2` library. 

- Provides basic functions that enable us to perform a considerable amount of
  common web scraping tasks. For instance, extracting text and/or tables from
  web pages.
  
- What you can do with web scraping will depend on your creativity and how the
  data you want to extract is stored in the "target" website.
  
- Some websites are "protected" against web scraping in the sense that the
  developers of these sites make everything in their power to make it difficult
  to scrape their data. Some examples are betting platforms such as bet365, for
  example.

---

## Basic functions

- For most of the time we will be using only 5 functions from this package.

- `read_html`: reads a web page and stores it into an `R` object of class
  `"xml_document"`.

- `html_element` and `html_elements`: these two functions will be the most
  important ones for most of the examples we work with. Basically, we will use
  these functions to select the "tags" we are interested in. 

- `html_table` parses an `html` table into a `data.frame`

- `html_text` and `html_text2` parses `html` text into character vectors.

---

## Good practices

- Scrape responsabily and, more importantly, respect the data sources.

- Don't try to use web scraping to emulate a "web crawler".

- Collect only what you need.

- Use an API if there is one available. 

- Collect only once if possible.

&gt; From https://jakobtures.github.io/web-scraping/goodpractice.html .

---

class: middle, center, inverse

# Examples


---

## FIFA World Cup (Wikipedia)

* Web scraping data from https://en.wikipedia.org/wiki/FIFA_World_Cup .


```r
library(dplyr)
library(ggplot2)
library(rvest)

## website url
url_wiki &lt;- 'https://en.wikipedia.org/wiki/FIFA_World_Cup'
## xpath for table
xpt_wiki &lt;- '/html/body/div[3]/div[3]/div[5]/div[1]/table[3]'

## reading html
page_wiki &lt;- read_html(url_wiki)
```

---

## FIFA World Cup (Wikipedia)

.pull-left[

```r
## all the text from the webpage
* page_wiki |&gt; 
*     html_elements("p") |&gt; 
*     html_text2() 

## all the tables from the page
page_wiki |&gt;
    html_elements("table") |&gt;
    html_table()
```
]

.pull-right[

```
## [1] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
## [2] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
## [3] "The FIFA World Cup, often simply called the World Cup, is an international association football competition contested by the senior men's national teams of the members of the Fédération Internationale de Football Association (FIFA), the sport's global governing body. The championship has been awarded every four years since the inaugural tournament in 1930, except in 1942 and 1946 when it was not held because of the Second World War. The current champion is France, which won its second title at the 2018 tournament in Russia."
## [4] "The current format involves a qualification phase, which takes place over the preceding three years, to determine which teams qualify for the tournament phase. In the tournament phase, 32 teams, including the automatically qualifying host nation(s), compete for the title at venues within the host nation(s) over about a month."                                                                                                                                                                                                          
## [5] "The 21 World Cup tournaments have been won by eight national teams. Brazil have won five times, and they are the only team to have played in every tournament. The other World Cup winners are Germany and Italy, with four titles each; Argentina, France, and inaugural winner Uruguay, with two titles each; and England and Spain, with one title each."                                                                                                                                                                                      
## [6] "The World Cup is the most prestigious association football tournament in the world, as well as the most widely viewed and followed single sporting event in the world. The cumulative viewership of all matches of the 2006 World Cup was estimated to be 26.29 billion with an estimated 715.1 million people watching the final match, a ninth of the entire population of the planet.[1][2][3][4]"
```
]

---

## FIFA World Cup (Wikipedia)

.pull-left[

```r
## all the text from the webpage
page_wiki |&gt;
    html_elements("p") |&gt;
    html_text2()

## all the tables from the page
* page_wiki |&gt; 
*     html_elements("table") |&gt; 
*     html_table() 
```
]

.pull-right[

```
## # A tibble: 9 × 2
##   X1                                X2                               
##   &lt;chr&gt;                             &lt;chr&gt;                            
## 1 FIFA World Cup Trophy             FIFA World Cup Trophy            
## 2 Founded                           1930; 91 years ago (1930)        
## 3 Region                            International (FIFA)             
## 4 Number of teams                   32 (finals)                      
## 5 Current champions                 France (2nd title)               
## 6 Most successful team(s)           Brazil (5 titles)                
## 7 Television broadcasters           List of broadcasters             
## 8 Website                           Official website                 
## 9 2022 FIFA World Cup qualification 2022 FIFA World Cup qualification
```
]

---

## FIFA World Cup (Wikipedia)


```r
## selecting an specific table
tbl_wiki &lt;-
    page_wiki |&gt;
    html_element(xpath = xpt_wiki) |&gt;
    html_table(dec = ",")

## dealing with double header
names(tbl_wiki) &lt;- as.character(tbl_wiki[1, ])
tbl_wiki &lt;- tbl_wiki[-1, ]

## removing "overall" row
tbl_wiki &lt;- tbl_wiki[-nrow(tbl_wiki), ]

tbl_wiki &lt;- janitor::clean_names(tbl_wiki)
```

---

## FIFA World Cup (Wikipedia)


```r
tbl_wiki &lt;-
    tbl_wiki |&gt;
    mutate_at(c(1, 4:6), ~ as.numeric(gsub(",", "", .))) |&gt;
    mutate(number = as.numeric(substr(gsub(",", "", number), 1, 6)))
```

---

## FIFA World Cup (Wikipedia)

.pull-left[

```r
ggplot(data = tbl_wiki,
       aes(x = year, y = avg_attendance)) +
    geom_line(lwd = 1.1) +
    geom_label(aes(label = hosts)) +
    theme_bw()
```
]

.pull-right[
&lt;img src="index_files/figure-html/wiki8-1.png" width="85%" /&gt;
]

---

## FIFA World Cup (Wikipedia)


.pull-left[

```r
ggplot(data = tbl_wiki,
       aes(x = year, y = number)) +
    geom_line(lwd = 1.1) +
    ## geom_label(aes(label = gsub(",", "\n",venue))) +
    geom_label(aes(label = hosts)) +
    theme_bw()
```
]

.pull-right[
&lt;img src="index_files/figure-html/wiki10-1.png" width="85%" /&gt;
]

---

class: middle

## Exercise: Use `rvest` to load the table containing the top goal scorers in the Wikipedia page from the previous example.

---

## ATP tour Elo ratings

* Web scraping data from http://tennisabstract.com/reports/atp_elo_ratings.html


```r
url_elo &lt;- "http://tennisabstract.com/reports/atp_elo_ratings.html"
webpage &lt;- read_html(url_elo)

* webpage 
```

---



```
## {html_document}
## &lt;html&gt;
## [1] &lt;head&gt;\n&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] &lt;body&gt;\r\n&lt;table width="100%"&gt;&lt;tr&gt;\n&lt;td align="left"&gt; &lt;/td&gt;\r\n&lt;td align= ...
## [3] &lt;script type="text/javascript" src="http://www.minorleaguesplits.com/tenn ...
## [4] &lt;script type="text/javascript" src="http://www.minorleaguesplits.com/tenn ...
## [5] &lt;script type="text/javascript" src="http://www.minorleaguesplits.com/tenn ...
## [6] &lt;script type="text/javascript" src="http://www.minorleaguesplits.com/tenn ...
## [7] &lt;script type="text/javascript" src="http://www.minorleaguesplits.com/tenn ...
## [8] &lt;script language="JavaScript"&gt;\r\n    $('#playersearch').append($('&lt;input ...
```

---

## ATP tour Elo ratings

* Web scraping data from http://tennisabstract.com/reports/atp_elo_ratings.html


```r
url_elo &lt;- "http://tennisabstract.com/reports/atp_elo_ratings.html"
webpage &lt;- read_html(url_elo)

webpage

elo_class &lt;- webpage |&gt;
  html_element(".tablesorter") |&gt;
  html_table()

* elo_class 
```

---


```
## # A tibble: 6 × 16
##    Rank Player        Age   Elo ``    HardRaw ClayRaw GrassRaw ``     hElo  cElo
##   &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;    &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     1 Novak Djok…  34.3 2173  NA    2041.3  2036.0  1962.5   NA    2107. 2104.
## 2     2 Daniil Med…  25.5 2144. NA    2092.6  1713.9  1723.4   NA    2118. 1929.
## 3     3 Alexander …  24.4 2111. NA    2023.5  1998.9  1671.4   NA    2067. 2055 
## 4     4 Rafael Nad…  35.2 2095. NA    1891.6  2050.9  1563.0   NA    1993. 2073.
## 5     5 Stefanos T…  23   2072. NA    1931.2  2005.2  1543.4   NA    2002. 2038.
## 6     6 Roger Fede…  39.9 2043. NA    1935.8  1749.3  1813.4   NA    1989. 1896.
## # … with 5 more variables: gElo &lt;dbl&gt;,  &lt;lgl&gt;, Peak Match &lt;chr&gt;,
## #   Peak Age &lt;dbl&gt;, Peak Elo &lt;dbl&gt;
```

---

## ATP tour Elo ratings

* Web scraping data from http://tennisabstract.com/reports/atp_elo_ratings.html


```r
url_elo &lt;- "http://tennisabstract.com/reports/atp_elo_ratings.html"
webpage &lt;- read_html(url_elo)

webpage

elo_class &lt;- webpage |&gt;
  html_element(".tablesorter") |&gt;
  html_table()

elo_id &lt;- webpage |&gt;
  html_element("#reportable") |&gt;
  html_table()

* elo_id 
```

---


```
## # A tibble: 6 × 16
##    Rank Player        Age   Elo ``    HardRaw ClayRaw GrassRaw ``     hElo  cElo
##   &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;    &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     1 Novak Djok…  34.3 2173  NA    2041.3  2036.0  1962.5   NA    2107. 2104.
## 2     2 Daniil Med…  25.5 2144. NA    2092.6  1713.9  1723.4   NA    2118. 1929.
## 3     3 Alexander …  24.4 2111. NA    2023.5  1998.9  1671.4   NA    2067. 2055 
## 4     4 Rafael Nad…  35.2 2095. NA    1891.6  2050.9  1563.0   NA    1993. 2073.
## 5     5 Stefanos T…  23   2072. NA    1931.2  2005.2  1543.4   NA    2002. 2038.
## 6     6 Roger Fede…  39.9 2043. NA    1935.8  1749.3  1813.4   NA    1989. 1896.
## # … with 5 more variables: gElo &lt;dbl&gt;,  &lt;lgl&gt;, Peak Match &lt;chr&gt;,
## #   Peak Age &lt;dbl&gt;, Peak Elo &lt;dbl&gt;
```

---

## College Football

* Web scraping data from http://www.cfbstats.com/2009/leader/national/team/offense/split01/category09/sort01.html .

.pull-left[

```r
url_cf  &lt;- "http://www.cfbstats.com/2009/leader/national/team/offense/split01/category09/sort01.html"
page_cf &lt;- read_html(url_cf)

cg_2009 &lt;-
    page_cf |&gt;
    html_element("table") |&gt;
    html_table() |&gt;
    janitor::clean_names() |&gt;
    rename("rank" = "x")

* head(cg_2009) 
```
]

.pull-right[

```
## # A tibble: 6 × 10
##    rank name            g    td    fg  x1xp  x2xp safety points points_g
##   &lt;int&gt; &lt;chr&gt;       &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;
## 1     1 Houston        14    77    20    65     2      0    591     42.2
## 2     1 Boise State    14    76    19    66     5      1    591     42.2
## 3     3 Texas          14    68    24    66     1      1    550     39.3
## 4     4 Cincinnati     13    66    13    63     1      1    502     38.6
## 5     5 TCU            13    65    15    61     0      1    498     38.3
## 6     6 Nevada         13    69     6    61     2      0    497     38.2
```
]

---

## College Football

* Sometimes, the URL of the website we are scraping follow some patterns. For
  example, for this example we can see the year as a parameter in the URL, that
  is
  _http://www.cfbstats.com/**2009**/leader/national/team/offense/split01/category09/sort01.html_
  
* In this case, specifically, we can just change the year in the url to scrape
  data from a different year. Take a look at the chunk of code below and compare
  it to the url stored in the `url_cf` object.
  

```r
url_cf2  &lt;- "http://www.cfbstats.com/{{2010}}/leader/national/team/offense/split01/category09/sort01.html"
```

---

class: middle

## Exercise: Use what we have learned so far to scrape the stats for every year between 2009 and 2020 in the  College Fooball example

---

## Solution


```r
urls_aux &lt;- "http://www.cfbstats.com/%d/leader/national/team/offense/split01/category09/sort01.html"

tables_cf &lt;- lapply(2009:2020,
                    function(x, .url) {
                        url &lt;- sprintf(.url, x)
                        
                        out &lt;- read_html(url) |&gt;
                            html_element("table") |&gt;
                            html_table() |&gt;
                            janitor::clean_names() |&gt;
                            rename("rank" = "x") |&gt;
                            mutate(year = x) |&gt;
                            select(rank, year, name, everything())

                        return(out)
                    }, .url = urls_aux)

final_table &lt;- bind_rows(tables_cf)
```

---

## Solution

&lt;img src="index_files/figure-html/plot_solution-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle

## Exercise: web scrape the tables from this url https://www.baseball-almanac.com/teamstats/schedule.php?y=2014&amp;t=BOS for different years. 

---


## Web Scraping for Dynamic Data in R

* What dynamic data display in the website can be changed in response to the
  user interaction.

* We need to automate the web browsing process in R for the dynamic data.

* **RSelenium** package helps this automating process by providing connection to
  Selenium Server.

* This package requires us to set up a local server, this process varies with
  the OS you're using. The authors right now recommend using docker to do
  so. For more information see [this
  link](https://docs.ropensci.org/RSelenium/articles/docker.html)

* Install **RSelenium** package.


```r
install.packages("RSelenium")
library("RSelenium")
```

---

## Web Scraping for Dynamic Data in R

* Use **RSelenium** to extract data on [2017 Australian Open
  Final](http://www.flashscore.com/match/Cj6I5iL9/#match-statistics;0)

&lt;img src="img/flashscore.png" width="85%" style="display: block; margin: auto;" /&gt;

---

## Web Scraping for Dynamic Data in R

.pull-left[
* Connect to a selenium server and open brower. (This varies according to your
  operational system)


```r
rD &lt;- rsDriver(port = 5561L, chromever = "85.0.4183.87")
remDr &lt;- rD$client
```

* Extract Information and organize data.


```r
url &lt;- "http://www.flashscore.com/match/Cj6I5iL9/#match-statistics;0"
remDr$navigate(url)
webElem &lt;- remDr$findElements(using = 'class', "statBox")
webElem &lt;- unlist(lapply(webElem, function(x){x$getElementText()}))[[1]]
# head(unlist(strsplit(webElem, split = '\n')))
remDr$close()
```
]

.pull-right[
&lt;img src="img/rselres.png" width="85%" style="display: block; margin: auto;" /&gt;
]

---

## Web Scraping for Dynamic Data in R

* Frequently used functions of **RSelenium**:

  - rsDriver() : start a selenium server
  - navigate() : navigate web pages
  - findElements() : find elements by CSS seclector or XPATH
  - getPageSource() : get current page source
  - clickElement() : click element
  
* Please go to [RSelenium
  cran](https://cran.r-project.org/web/packages/RSelenium/RSelenium.pdf) for
  more details.

---

## Web Scraping for Dynamic Data in R

Exercise: Web Scraping for the history basketball recording of UConn

https://www.flashscore.com/team/connecticut-huskies/8rqVf3Tj/results/

* Start a selenium server and open web brower.


```r
require("RSelenium")
rD &lt;- rsDriver(port = 5533L, chromever = "85.0.4183.87")
remDr &lt;- rD$client
url &lt;- "https://www.flashscore.com/team/connecticut-huskies/8rqVf3Tj/results/#"
remDr$navigate(url)
```

---

## Web Scraping for Dynamic Data in R

.pull-left[
* Automate to click all "show more results".


```r
repeat{
  b &lt;- tryCatch({
    suppressMessages({
      webElemMore &lt;- remDr$findElement(using = 'xpath', 
                        '//*[@id="live-table"]/div[1]/div/div/a')
      webElemMore$clickElement()
    })
  }, error = function(e) e)
  if(inherits(b, "error")) break
}
```
]

--

.pull-right[
* Extract data, such as time, home/away, score and result.


```r
webElemTime &lt;- remDr$findElements(using = 'xpath', 
                              '//*[@class="event__time"]')
webElemTime &lt;- 
  unlist(lapply(webElemTime, function(x){x$getElementText()}))
webElemTime &lt;- gsub("\\n", " ", webElemTime)
```
]

---

## Web Scraping for Dynamic Data in R


```r
webElemHome &lt;- 
  remDr$findElements(using = 'class', 
                     'event__participant')
webElemHome &lt;- 
  unlist(lapply(webElemHome, function(x){x$getElementText()}))
webElemScore &lt;- 
  remDr$findElements(using = 'class', 'event__score')
webElemScore &lt;- 
  unlist(lapply(webElemScore, function(x){x$getElementText()}))
webElemResult &lt;- 
  remDr$findElements(using = 'class', 'wld')
webElemResult &lt;- 
  unlist(lapply(webElemResult, function(x){x$getElementText()}))
```

---

## Web Scraping for Dynamic Data in R

.pull-left[

* Organizing dataset.


```r
n &lt;- length(webElemHome)
basketball &lt;- 
  data.frame(time = webElemTime,
             Home = webElemHome[seq(n) %% 2 == 1],
             Away = webElemHome[seq(n) %% 2 == 0],
             HomeS = webElemScore[seq(n) %% 2 == 1],
             AwayS = webElemScore[seq(n) %% 2 == 0],
             Result = webElemResult)
head(basketball)
remDr$close()
```
]

.pull-right[
&lt;img src="img/uconn.png" width="85%" style="display: block; margin: auto;" /&gt;
]

---

## Summary

* For different kinds of data, we need to use different web scraping techiniques
  with R.

* One can simply use **read.csv** or related functions to directly import
  organized files from web pages.

* The static data can be extract with the help of **rvest**.

* We could use **RSelenium** to parse the dynamic data.

---

## Resources

- [CSS and HTML crash course](http://flukeout.github.io/)

- [rvest](https://rvest.tidyverse.org/)

- [RSelenium](https://cran.r-project.org/web/packages/RSelenium/vignettes/basics.html)

- [R task view: web
  technology](https://cran.r-project.org/web/views/WebTechnologies.html)


---

## Acknowledgement

This slides are modified from [Dr. Kovalchik's
material](https://github.com/skoval/UseRSportTutorial), [Wanwan Xu's
slides](https://github.com/wanwanx/WebScraping_UCSAS), [Yaqiong Yao's
slides](https://github.com/yay17007/UCSAS_WebScrapping).

---

class:: middle, center, inverse

# Get in touch!

## <svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"/></svg> [lcgodoy.me](lcgodoy.me)

## <svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> [ldcgodoy](https://twitter.com/ldcgodoy)

## <svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> [lcgodoy](https://github.com/lcgodoy)

## <svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg> lucasdac.godoy@gmail.com
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "monokai-sublime",
"highlightLines": true,
"countIncrementalSlides": false,
"seal": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
